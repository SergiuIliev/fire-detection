{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calculate historical risk values** using *risk_calculation.py*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Insert brightness_MODIS: 100%|██████████████████████████████████████████████| 708008/708008 [00:26<00:00, 26665.94it/s]\n",
      "Insert brightness_VIIRS: 100%|██████████████████████████████████████████████| 708008/708008 [00:28<00:00, 25184.46it/s]\n",
      "Calculate the average: 100%|████████████████████████████████████████████████| 708008/708008 [00:18<00:00, 38025.56it/s]\n",
      "Calculate Time Range: 100%|█████████████████████████████████████████████████| 708008/708008 [01:00<00:00, 11631.42it/s]\n",
      "Generate the final Risk: 100%|█████████████████████████████████████████████| 708008/708008 [00:01<00:00, 602105.30it/s]\n"
     ]
    }
   ],
   "source": [
    "# Calculate risk function - same as risk_calculation.py, just this time average_brightness is stored as a variable\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast\n",
    "import time\n",
    "import datetime\n",
    "import statistics \n",
    "from tqdm import tqdm\n",
    "\n",
    "# function\n",
    "def calculateDays(date1, date2):\n",
    "    day1 = time.strptime(date1, \"%Y-%m-%d\")\n",
    "    day1 = datetime.datetime(day1[0], day1[1], day1[2])\n",
    "    day2 = time.strptime(date2, \"%Y-%m-%d\")\n",
    "    day2 = datetime.datetime(day2[0], day2[1], day2[2])\n",
    "    #today = datetime.datetime.today()\n",
    "    interval = day1 - day2\n",
    "    return interval.days\n",
    "\n",
    "# read the cleaned and procesed data\n",
    "c_df = pd.read_csv('data/combined_dataframes.csv')\n",
    "\n",
    "# Convert the contents of the pandas array from strings looking like lists to actual lists\n",
    "brightness_MODIS = c_df.loc[:,'bright_ti4'].apply(ast.literal_eval)\n",
    "brightness_VIIRS = c_df.loc[:,'bright_ti5'].apply(ast.literal_eval)\n",
    "instrument = c_df.loc[:,'instrument'].apply(ast.literal_eval)\n",
    "\n",
    "# Initialise the risk vector\n",
    "risk = np.zeros(len(c_df.latitude))\n",
    "\n",
    "for i,list in enumerate(tqdm(iterable = brightness_MODIS, desc = \"Insert brightness_MODIS\")):\n",
    "    risk[i] += statistics.mean(list)\n",
    "\n",
    "for i,list in enumerate(tqdm(iterable = brightness_VIIRS, desc = \"Insert brightness_VIIRS\")):\n",
    "    risk[i] += statistics.mean(list)\n",
    "\n",
    "# Calculate the average of each of the brightnesses\n",
    "for i,list in enumerate(tqdm(iterable = risk, desc = \"Calculate the average\")):\n",
    "    risk[i] = risk[i] / len(instrument[i]) # divide by the number of instruments i.e. mean of 1 or mean of 2\n",
    "average_brightness = risk.copy()\n",
    "\n",
    "timeRange = np.zeros(len(c_df.latitude))\n",
    "timeData = c_df[\"acq_date\"].apply(ast.literal_eval)\n",
    "for i, value in enumerate(tqdm(iterable = timeData, desc = \"Calculate Time Range\")):\n",
    "    # if only one day, the result will be the difference between that and the date today\n",
    "    if len(value) == 1:\n",
    "        timeRange[i] = abs(calculateDays(\"2020-02-15\",timeData[i][0]))\n",
    "    # if more than one day, the result will be the difference between the start day and the end day\n",
    "    elif len(value) > 1:\n",
    "        # start day\n",
    "        date1 = timeData[i][0]\n",
    "        # end day\n",
    "        date2 = timeData[i][-1]\n",
    "        timeRange[i] = abs(calculateDays(date2,date1))\n",
    "# divided by the time range\n",
    "for i,list in enumerate(tqdm(iterable = risk, desc = \"Generate the final Risk\")):\n",
    "    risk[i] = risk[i] / timeRange[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import required packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import time\n",
    "import pandas as pd \n",
    "import ast\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from visualisation import generate_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define the imput dataset to the Machine Learning Code from the historical risk values and cleaned data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>timeRange</th>\n",
       "      <th>avg_brightness</th>\n",
       "      <th>risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>708003</td>\n",
       "      <td>-10.16375</td>\n",
       "      <td>142.13250</td>\n",
       "      <td>64.0</td>\n",
       "      <td>629.0</td>\n",
       "      <td>9.828125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>708004</td>\n",
       "      <td>-10.16375</td>\n",
       "      <td>142.14375</td>\n",
       "      <td>54.0</td>\n",
       "      <td>636.6</td>\n",
       "      <td>11.788889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>708005</td>\n",
       "      <td>-10.16375</td>\n",
       "      <td>142.14750</td>\n",
       "      <td>54.0</td>\n",
       "      <td>611.1</td>\n",
       "      <td>11.316667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>708006</td>\n",
       "      <td>-10.09625</td>\n",
       "      <td>142.16250</td>\n",
       "      <td>130.0</td>\n",
       "      <td>605.8</td>\n",
       "      <td>4.660000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>708007</td>\n",
       "      <td>-9.39875</td>\n",
       "      <td>142.64625</td>\n",
       "      <td>75.0</td>\n",
       "      <td>657.9</td>\n",
       "      <td>8.772000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        latitude  longitude  timeRange  avg_brightness       risk\n",
       "708003 -10.16375  142.13250       64.0           629.0   9.828125\n",
       "708004 -10.16375  142.14375       54.0           636.6  11.788889\n",
       "708005 -10.16375  142.14750       54.0           611.1  11.316667\n",
       "708006 -10.09625  142.16250      130.0           605.8   4.660000\n",
       "708007  -9.39875  142.64625       75.0           657.9   8.772000"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.concat([c_df.latitude, c_df.longitude,\n",
    "                     pd.DataFrame(timeRange, columns=['timeRange']), \n",
    "                     pd.DataFrame(average_brightness, columns=['avg_brightness']),\n",
    "                     pd.DataFrame(risk, columns=['risk'])],\n",
    "                    axis = 1)\n",
    "dataset.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 708008 entries, 0 to 708007\n",
      "Data columns (total 5 columns):\n",
      "latitude          708008 non-null float64\n",
      "longitude         708008 non-null float64\n",
      "timeRange         708008 non-null float64\n",
      "avg_brightness    708008 non-null float64\n",
      "risk              708008 non-null float64\n",
      "dtypes: float64(5)\n",
      "memory usage: 27.0 MB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>timeRange</th>\n",
       "      <th>avg_brightness</th>\n",
       "      <th>risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>latitude</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.399392</td>\n",
       "      <td>0.471623</td>\n",
       "      <td>0.178046</td>\n",
       "      <td>-0.166792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>longitude</td>\n",
       "      <td>-0.399392</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.287636</td>\n",
       "      <td>-0.274887</td>\n",
       "      <td>0.188372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>timeRange</td>\n",
       "      <td>0.471623</td>\n",
       "      <td>-0.287636</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.138290</td>\n",
       "      <td>-0.653684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>avg_brightness</td>\n",
       "      <td>0.178046</td>\n",
       "      <td>-0.274887</td>\n",
       "      <td>0.138290</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.118145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>risk</td>\n",
       "      <td>-0.166792</td>\n",
       "      <td>0.188372</td>\n",
       "      <td>-0.653684</td>\n",
       "      <td>-0.118145</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                latitude  longitude  timeRange  avg_brightness      risk\n",
       "latitude        1.000000  -0.399392   0.471623        0.178046 -0.166792\n",
       "longitude      -0.399392   1.000000  -0.287636       -0.274887  0.188372\n",
       "timeRange       0.471623  -0.287636   1.000000        0.138290 -0.653684\n",
       "avg_brightness  0.178046  -0.274887   0.138290        1.000000 -0.118145\n",
       "risk           -0.166792   0.188372  -0.653684       -0.118145  1.000000"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = dataset[['latitude', 'longitude', 'timeRange', 'avg_brightness']]\n",
    "labels = dataset['risk']\n",
    "mean_values = features.describe().iloc[1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed to ensure reproducible runs\n",
    "RSEED = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Machine Learning Approach 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size = 0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.0019263785299654583\n"
     ]
    }
   ],
   "source": [
    "# train our dataset on the train data and analyse our Mean Absolute Error on the test data.\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "clf = RandomForestRegressor(verbose=True) # enable a progress bar\n",
    "clf = RandomForestRegressor(n_estimators = 100, max_depth = 50)\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"Mean Absolute Error: {}\".format(mean_squared_error(y_test, clf.predict(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=50,\n",
       "                      max_features='auto', max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=1, min_samples_split=2,\n",
       "                      min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                      n_jobs=None, oob_score=False, random_state=None,\n",
       "                      verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model on the complete dataset and then simply use the post endpoint to get the risk\n",
    "endpoint_classifier = RandomForestRegressor(n_estimators = 100, max_depth = 50)\n",
    "endpoint_classifier.fit(fetched_data.data, fetched_data.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Machine Learning Approach 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: 'continuous'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-128-732f8ad5af10>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# Fit on training data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Programs\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    273\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    274\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 275\u001b[1;33m         \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexpanded_class_weight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_y_class_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    276\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    277\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"dtype\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mDOUBLE\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Programs\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36m_validate_y_class_weight\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    476\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    477\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_validate_y_class_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 478\u001b[1;33m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    479\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    480\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Programs\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\multiclass.py\u001b[0m in \u001b[0;36mcheck_classification_targets\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m    167\u001b[0m     if y_type not in ['binary', 'multiclass', 'multiclass-multioutput',\n\u001b[0;32m    168\u001b[0m                       'multilabel-indicator', 'multilabel-sequences']:\n\u001b[1;32m--> 169\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Unknown label type: %r\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Unknown label type: 'continuous'"
     ]
    }
   ],
   "source": [
    "# https://github.com/WillKoehrsen/Machine-Learning-Projects/blob/master/Random%20Forest%20Tutorial.ipynb\n",
    "    \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Extract the labels\n",
    "labels = np.array(df.pop('label'))\n",
    "\n",
    "# 30% examples in test data\n",
    "train, test, train_labels, test_labels = train_test_split(df, labels, \n",
    "                                                          stratify = labels,\n",
    "                                                          test_size = 0.3, \n",
    "                                                          random_state = RSEED)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create the model with 100 trees\n",
    "model = RandomForestClassifier(n_estimators=100, \n",
    "                               random_state=RSEED, \n",
    "                               max_features = 'sqrt',\n",
    "                               n_jobs=-1, verbose = 1)\n",
    "\n",
    "# Fit on training data\n",
    "model.fit(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
